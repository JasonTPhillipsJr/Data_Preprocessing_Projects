{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c7d251",
      "metadata": {
        "id": "10c7d251"
      },
      "outputs": [],
      "source": [
        "#Project 3 part\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import stats\n",
        "import graphviz\n",
        "\n",
        "def normalize_numeric_minmax(df, name):\n",
        "        df[name] = ((df[name] - df[name].min()) / (df[name].max() - df[name].min())).astype(np.float32)\n",
        "        \n",
        "def read_data():\n",
        "    '''\n",
        "    Read data from the path provides!\n",
        "    '''\n",
        "    df = pd.read_csv(\"bottle.csv\")  \n",
        "    \n",
        "    return df\n",
        "\n",
        "def clean(df):\n",
        "    '''\n",
        "    Cleans the data!\n",
        "    '''\n",
        "    df = df[[\"T_degC\", \"Salnty\"]]\n",
        "    df.rename(columns={\n",
        "        \"T_degC\": \"Temperature(deg)\",\n",
        "        \"Salnty\": \"Salinity\"\n",
        "    }, inplace=True)\n",
        "    return df\n",
        "\n",
        "def impute(df):\n",
        "    \"\"\"\n",
        "    Functions to empute none values!\n",
        "    \"\"\"\n",
        "    for name in df.select_dtypes(\"number\"):\n",
        "        df[name] = df[name].fillna(method=\"ffill\")\n",
        "        \n",
        "    for name in df.select_dtypes(\"category\"):\n",
        "        df[name] = df[name].fillna(\"None\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \n",
        "    # Reading data\n",
        "    df = read_data() \n",
        "    \n",
        "    # Preprocessing data\n",
        "    df = clean(df)\n",
        "    \n",
        "    df = impute(df)\n",
        "    #df_cast = impute(df_cast)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Loading the data\n",
        "bottle_data = load_data()\n",
        "\n",
        "# Looking at a data\n",
        "bottle_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63aafe5",
      "metadata": {
        "id": "b63aafe5"
      },
      "outputs": [],
      "source": [
        "bottle_data = bottle_data[:10000]\n",
        "bottle_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd438f9b",
      "metadata": {
        "id": "fd438f9b"
      },
      "outputs": [],
      "source": [
        "normalize_numeric_minmax(bottle_data,'Temperature(deg)')\n",
        "normalize_numeric_minmax(bottle_data,'Salinity')\n",
        "bottle_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60f5184b",
      "metadata": {
        "id": "60f5184b"
      },
      "outputs": [],
      "source": [
        "bottle_data.loc[(bottle_data['Temperature(deg)'] < .25), 'Temperature(deg)'] = -2\n",
        "bottle_data.loc[(bottle_data['Temperature(deg)'] >= .25), 'Temperature(deg)'] = -1\n",
        "\n",
        "\n",
        "bottle_data['Temperature(deg)'] = bottle_data['Temperature(deg)'].replace([-1], 'Hot')\n",
        "bottle_data['Temperature(deg)'] = bottle_data['Temperature(deg)'].replace([-2], 'Not Hot')\n",
        "bottle_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3074e4e",
      "metadata": {
        "id": "b3074e4e"
      },
      "outputs": [],
      "source": [
        "#Setup the training and testing data.\n",
        "numInstances = 10000\n",
        "numTrain = 2000\n",
        "numTest = numInstances - numTrain\n",
        "\n",
        "#Create the training and testing datasets.\n",
        "trainingData = bottle_data[:numTest]\n",
        "testData = bottle_data[numTest:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0f531c",
      "metadata": {
        "id": "aa0f531c"
      },
      "outputs": [],
      "source": [
        "trainX = pd.DataFrame(trainingData, columns = [\"Salinity\"])\n",
        "trainY = trainingData.drop([\"Salinity\"], axis = 1)\n",
        "\n",
        "testX = pd.DataFrame(testData, columns = [\"Salinity\"])\n",
        "testY = testData.drop([\"Salinity\"], axis = 1)\n",
        "\n",
        "trainX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "707da538",
      "metadata": {
        "id": "707da538"
      },
      "outputs": [],
      "source": [
        "#Creating the Classification Tree\n",
        "clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 3) #We should keep an eye on the max depth to adjust the tree.\n",
        "clf = clf.fit(trainX,trainY)\n",
        "\n",
        "\n",
        "#Create the data for the graph\n",
        "dot_data = tree.export_graphviz(clf, out_file = None, feature_names = trainX.columns, class_names = ['Not Hot', 'Hot'],\n",
        "                                filled = True, rounded = True, special_characters = True)\n",
        "#Create the graph to display the data.\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33d9e1e3",
      "metadata": {
        "id": "33d9e1e3"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy = %f\" % clf.score(testX,testY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119a4e41",
      "metadata": {
        "id": "119a4e41"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression (With a parameter C.)\n",
        "C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]\n",
        "\n",
        "#Create two arrays for the logistic accuracy for both training and testing sets.\n",
        "LRtestAcc = []\n",
        "LRtrainAcc = []\n",
        "\n",
        "#For loop to use each weight to predict the proper output. The less weight, the less that the datapoints in X influence the outcome.\n",
        "for param in C:\n",
        "  clf = LogisticRegression(C = param)\n",
        "  clf.fit(testX,testY)\n",
        "  log_reg_pred = clf. predict(testX)\n",
        "  log_reg_pred_train = clf.predict(trainX)\n",
        "  #print(log_reg_pred)\n",
        "  LRtestAcc.append(accuracy_score(testY, log_reg_pred))\n",
        "  LRtrainAcc.append(accuracy_score(trainY,log_reg_pred_train))\n",
        "\n",
        "#Create a plot to visualize the logistic regression line and the accuracy of our models predictions.\n",
        "plt.plot(C, LRtestAcc,'bv--',C,LRtrainAcc,'ro--')\n",
        "plt.legend(['Test Accuracy','Train Accuracy'])\n",
        "plt.xlabel('C')\n",
        "plt.xscale('log')\n",
        "plt.ylabel('Accuracy')  \n",
        "\n",
        "\"\"\" This works but for the sake of the tutorial we will be using the parameter instead.\n",
        "clf = LogisticRegression(random_state = 0)\n",
        "clf.fit(trainX, trainY)\n",
        "\"\"\"\n",
        "clf.score(testX, testY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "014a2115",
      "metadata": {
        "id": "014a2115"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy = %f\" % clf.score(testX,testY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "955888b7",
      "metadata": {
        "id": "955888b7"
      },
      "outputs": [],
      "source": [
        "#SVM Non Linear Example\n",
        "#Creating the arrays for the accuracy of the test and trainning sets.\n",
        "SVMLtestAcc = [] \n",
        "SVMLtrainAcc = []\n",
        "\n",
        "#predY = clf.predict(testX)\n",
        "#print('Accuracy on test data is %.2f' % (accuracy_score(testY, predY)))\n",
        "\n",
        "#For loop to iterate each weight we place on the models data.\n",
        "for param in C:\n",
        "   clf = SVC(C=param, kernel='rbf', gamma='auto') \n",
        "   clf.fit(trainX,trainY) \n",
        "   svml_pred = clf.predict(testX) \n",
        "   svml_pred_train = clf.predict(trainX)\n",
        "   SVMLtestAcc.append(accuracy_score(testY, svml_pred)) \n",
        "   SVMLtrainAcc.append(accuracy_score(trainY,svml_pred_train))\n",
        "\n",
        "plt.plot(C, SVMLtestAcc,'ro--', C,SVMLtrainAcc,'bv--') \n",
        "plt.legend(['Test Accuracy','Train Accuracy']) \n",
        "plt.xlabel('C') \n",
        "plt.xscale('log') \n",
        "plt.ylabel('Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a56b752",
      "metadata": {
        "id": "6a56b752"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy = %f\" % clf.score(testX,testY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ed970e",
      "metadata": {
        "id": "e0ed970e"
      },
      "outputs": [],
      "source": [
        "#---Naive Bayes---\n",
        "\n",
        "clf_NB = GaussianNB()\n",
        "clf_NB.fit(trainX,trainY)\n",
        "NB_pred = clf_NB.predict(testX)\n",
        "print('Accuracy on test data is %.2f' % (accuracy_score(testY, NB_pred)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4972376",
      "metadata": {
        "id": "f4972376"
      },
      "outputs": [],
      "source": [
        "#K Nearest Neighbor\n",
        "numNeighbors = [1, 5, 10]\n",
        "testAcc = []\n",
        "trainAcc = []\n",
        "\n",
        "for k in numNeighbors:\n",
        "    clf = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n",
        "    clf.fit(trainX, trainY)\n",
        "    knn_pred = clf.predict(testX)\n",
        "    knn_pred_train = clf.predict(trainX)\n",
        "    testAcc.append(accuracy_score(testY, knn_pred))\n",
        "    trainAcc.append(accuracy_score(trainY,knn_pred_train))\n",
        "\n",
        "plt.plot(numNeighbors, testAcc,'bv--',numNeighbors, trainAcc, 'ro--')\n",
        "plt.legend(['Test Accuracy','Train Accuacy'])\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f41bf14",
      "metadata": {
        "id": "2f41bf14"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy = %f\" % clf.score(testX,testY))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Our_Data_Classification_Models.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}